

# 'isolation.level' must be 'read_committed' in consumers to enable exactly-once delivery.
# Additionally, it is highly recommended to tweak Kafka transaction timeout
# (see Kafka producer transaction.timeout.ms)
# maximum checkpoint duration + maximum restart duration or data loss may happen when Kafka expires an uncommitted transaction.

window {
  size.ms = ${?WIN_SIZE}
  step.ms = ${?WIN_STEP}
}

kafka {
  topic = ${KAFKA_TOPIC}
  servers = ${KAFKA_SERVERS}

  # 'group.id' will be the same as 'application.id'.
  # 'state.dir' will contain subdirectories for every 'application.id'.
  # You can keep 'application.id' to reuse the existing data in internal topics and state stores.
  application.id = ${?KAFKA_APP_ID}

  # Kafka Streams stores their state here.
  state.dir = ${?KAFKA_STATE}

  grace.period.ms = ${?KAFKA_GRACE_PERIOD}

}


flink {
  # Describes how much time Flink should wait before closing the window.
  # Conventional joins also support this capability.
  # Behaves closely to Kafka's grace period.
  allowed.lateness = ${?FLINK_ALLOWED_LATENESS}

  # Describes how late an out-of-order event can be.
  out.of.order.max.ms = ${?FLINK_MAX_OUT_OF_ORDER}

  # Consider using punctuated watermarking strategies for deterministic event-time driven outputs.
  auto.watermark.interval = ${?FLINK_AUTO_WMK_INT}

  # An idle partition in a topic can cause watermarks to stop propagating.
  idleness.ms = ${?FLINK_IDLENESS}

  # When Flink finishes writing the checkpoint,
  # it commits its messages to Kafka as a transaction.
  # Without the prefix, transactions can break each other.
  transaction.id.prefix = ${?FLINK_TRX_ID_PREFIX}

  # It should be a distributed reliable storage.
  checkpoint.storage = ${?FLINK_CP_STORAGE}

  # The data becomes available only when Flink finishes writing the checkpoint.
  # Decrease this time to have lower latency.
  checkpoint.ms = ${?FLINK_CP}
  checkpoint.timeout.ms = ${?FLINK_CP_TIMEOUT}

  # Describes the lowest interval between the checkpoints.
  checkpoint.pause.ms = ${?FLINK_CP_PAUSE}

  # Describes how many checkpoint failures Flink tolerates before aborting the job.
  checkpoint.tolerable.failure.num = ${?FLINK_CP_TOL_NUM}

  kafka {
    group.id = ${?FLINK_KAFKA_GROUP_ID}

    # Should be equal to the checkpoint time plus the restart time.
    # Should be set otherwise you will see no more records.
    transaction.timeout.ms = ${?FLINK_KAFKA_TRX_TIMEOUT}
  }

}

spark {

  watermark.ms = ${?SPARK_WMK_MS}

  checkpoint.location = ${?SPARK_CP_LOC}

  kafka {
    group.id = ${?SPARK_KAFKA_GROUP_ID}
  }

}


producer {

  # Controls the batch size in bytes.
  # When the batch is full the producer sends the batch to Kafka.
  batch.size = ${?BATCH_SIZE}

  # It may take too much time for the batch to become complete.
  # This property let us send the batch regardless of whether it is full or not.
  linger.ms = ${?LINGER}

  partition = ${PARTITION}

  # The number of clusters.
  cluster.num = ${?CLUSTERS}

  # The number of machines per cluster.
  machine.num = ${?MACHINES}

  # How fast each machine produces records.
  speed.ms = ${?SPEED}

  # This property enables randomness.
  dispersion.ms = ${?DISPERSION}

}